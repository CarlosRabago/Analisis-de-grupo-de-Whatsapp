{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de grupo de Whatsapp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autor: CARF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar Librerias\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import collections\n",
    "import emoji\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funciones de recuperación y limpieza\n",
    "\n",
    "def starts_with_date_time(s):\n",
    "    # regex pattern for date\n",
    "    pattern = r'^\\d{1,2}/\\d{1,2}/\\d{4}\\s\\d{1,2}:\\d{2}\\s[ap].\\sm\\.'\n",
    "    result = re.match(pattern, s)\n",
    "    if result:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se reconoce el nombre de usuario en cualquier formato registrado.\n",
    "def find_author(s):\n",
    "    patterns = [\n",
    "        '([\\w]+):',                        # Primer Nombre\n",
    "        '([\\w]+[\\s]+[\\w]+):',              # Primer Nombre + Apellido\n",
    "        '([\\w]+[\\s]+[\\w]+[\\s]+[\\w]+):',    # Primer Nombre + Seg. nombre + Apellido\n",
    "        '([+]\\d{2} \\d{3} \\d{3} \\d{4}):',   # Teléfono México\n",
    "        '[\\w]+ ?[^\\s\\u1f300-\\u1f5ff]:',    # Nombre y Emoji              \n",
    "    ]\n",
    "    pattern = '^' + '|'.join(patterns)\n",
    "    result = re.match(pattern, s)\n",
    "    if result:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_point(line):   \n",
    "    split_line = line.split(' - ') \n",
    "    date_time = split_line[0].split(' ') \n",
    "    date = date_time[0]\n",
    "    time = ' '.join(date_time[1:])\n",
    "    message = ' '.join(split_line[1:])\n",
    "    if find_author(message): \n",
    "        split_message = message.split(': ') \n",
    "        author = split_message[0] \n",
    "        message = ' '.join(split_message[1:])\n",
    "    else:\n",
    "        author = None\n",
    "    return date, time, author, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#Genera una lista con los datos para convertilos en data frame\n",
    "\n",
    "parsed_data = [] \n",
    "conversation_path = \"Chat.txt\" # chat file\n",
    "with open(conversation_path, encoding='utf8') as fp:\n",
    "    fp.readline() # Skipping first line of the file \n",
    "    message_buffer = [] \n",
    "    date, time, author = None, None, None\n",
    "    while True:\n",
    "        line = fp.readline() \n",
    "        if not line: \n",
    "            break\n",
    "        line = line.strip() \n",
    "        if starts_with_date_time(line): \n",
    "            print(line)\n",
    "            if len(message_buffer) > 0: \n",
    "                parsed_data.append([date, time, author, ' '.join(message_buffer)]) \n",
    "            message_buffer.clear() \n",
    "            date, time, author, message = get_data_point(line) \n",
    "            message_buffer.append(message) \n",
    "        else:\n",
    "            message_buffer.append(line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera el dataframe\n",
    "\n",
    "df = pd.DataFrame(parsed_data, columns=['Date', 'Time', 'Author', 'Message'])\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurando el Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], format= \"%d/%m/%y\") # Formato de fecha\n",
    "df['Message'] = df['Message'].str.lower() # Mensajes en minúsculas\n",
    "df['Message'] = df.Message.str.replace(r\"(a|j)?(ja)+(a|j)?\", \"jaja\") # Estandarizamos la expresión de risa a \"jaja\"\n",
    "df = df.dropna() # Para eliminar entradas en blanco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anonimizando Usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista con los personajes del Dc\n",
    "got_dt = pd.read_csv(\"DCpersonajes.csv\") \n",
    "\n",
    "# Obtiene nombres y alias\n",
    "nombres = list(df.Author.unique())\n",
    "aliases = list(got_dt.name.sample(len(nombres)))\n",
    "\n",
    "df.Author.replace(nombres, aliases, inplace=True) # Remplaza los autores por un alias\n",
    "\n",
    "# Remplaza las menciones de los miembros del grupo en la columna de mensajes en cada entrada en forma de string (por partes)\n",
    "for (nombre, alias) in zip(nombres, aliases):\n",
    "    df.Message = df.Message.str.replace(nombre, alias)\n",
    "    \n",
    "df.info()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "def split_count(text):\n",
    "\n",
    "    emoji_list = []\n",
    "    data = regex.findall(r'\\X', text)\n",
    "    for word in data:\n",
    "        if any(char in emoji.UNICODE_EMOJI for char in word):\n",
    "            emoji_list.append(word)\n",
    "\n",
    "    return emoji_list\n",
    "\n",
    "Autores= df.Author.unique()\n",
    "total_authors= Autores.shape[0]\n",
    "total_messages = df.shape[0]\n",
    "media_messages = df[df['Message'] == '<multimedia omitido>'].shape[0]\n",
    "df[\"emoji\"] = df[\"Message\"].apply(split_count)\n",
    "emojis = sum(df['emoji'].str.len())\n",
    "URLPATTERN = r'(https?://\\S+)'\n",
    "df['urlcount'] = df.Message.apply(lambda x: regex.findall(URLPATTERN, x)).str.len()\n",
    "links = np.sum(df.urlcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadísticas Generales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Estadísticas Generales del grupo\")\n",
    "print(\"La Cantidad de Autores del grupo es de \", total_authors,\", y el total de Mensajes es de \", total_messages,\".\")\n",
    "print(\"El Promedio de Mensajes enviados es de \",media_messages,\".\")\n",
    "print(\"La cantidad de Emojis enviados es de \",emojis,\", y el total de enlaces es de\",links,\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadisticas por autor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_messages_df = df[df['Message'] == '<multimedia omitido>']\n",
    "messages_df = df.drop(media_messages_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))\n",
    "messages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))\n",
    "messages_df[\"MessageCount\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = messages_df.Author.unique()\n",
    "\n",
    "for i in range(len(l)):\n",
    "  # Filtering out messages of particular user\n",
    "  req_df= messages_df[messages_df[\"Author\"] == l[i]]\n",
    "  # req_df will contain messages of only one particular user\n",
    "  print(f'Estadísticas de {l[i]} -')\n",
    "  # shape will print number of rows which indirectly means the number of messages\n",
    "  print('Mensajes enviados:', req_df.shape[0])\n",
    "  #Word_Count contains of total words in one message. Sum of all words/ Total Messages will yield words per message\n",
    "  words_per_message = (np.sum(req_df['Word_Count']))/req_df.shape[0]\n",
    "  print('Palabras por mensaje:', words_per_message)\n",
    "  #media conists of media messages\n",
    "  media = media_messages_df[media_messages_df['Author'] == l[i]].shape[0]\n",
    "  print('Contenido multimedia enviado:', media)\n",
    "  # emojis conists of total emojis\n",
    "  emojis = sum(req_df['emoji'].str.len())\n",
    "  print('Emojis enviados:', emojis)\n",
    "  #links consist of total links\n",
    "  links = sum(req_df[\"urlcount\"])   \n",
    "  print('Links enviados:', links)   \n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadisticas de Emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Total de Emojis distintos enviados dentro de la conversación\n",
    "total_emojis_list = list(set([a for b in messages_df.emoji for a in b]))\n",
    "total_emojis = len(total_emojis_list)\n",
    "print('Total de Emojis diferentes enviados:',total_emojis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emoji mas utilizado en el grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "total_emojis_list = list([a for b in messages_df.emoji for a in b])\n",
    "emoji_dict = dict(collections.Counter(total_emojis_list))\n",
    "emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "emoji_df = pd.DataFrame(emoji_dict, columns=['emoji', 'count'])\n",
    "emoji_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.pie(emoji_df, values='count', names='emoji',\n",
    "             title='Distribución por proporcón de Emojis')\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Crear lista de autores para crear gráficos de uso dee emoji's para cada autor\n",
    "l = messages_df.Author.unique()\n",
    "for i in range(len(l)):\n",
    "  dummy_df = messages_df[messages_df['Author'] == l[i]]\n",
    "  total_emojis_list = list([a for b in dummy_df.emoji for a in b])\n",
    "  emoji_dict = dict(collections.Counter(total_emojis_list))\n",
    "  emoji_dict = sorted(emoji_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "  print('Emoji Distribution for', l[i])\n",
    "  author_emoji_df = pd.DataFrame(emoji_dict, columns=['emoji', 'count'])\n",
    "  fig = px.pie(author_emoji_df, values='count', names='emoji')\n",
    "  fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "  fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autor_df = messages_df.groupby(\"Author\").sum()\n",
    "autor_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miembros con mayor actividad dentro del grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "messages_df['Author'].value_counts().head(15).plot.barh() \n",
    "plt.xlabel('Número de mensajes')\n",
    "plt.ylabel('Autor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actividad dentro de la linea de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_df = messages_df.groupby(\"Date\").sum()\n",
    "date_df.reset_index(inplace=True)\n",
    "fig = px.line(date_df, x=\"Date\", y=\"MessageCount\", labels={'Date':'Periodo', 'MessageCount':'No.Mensajes'}, title='Variación de la Actividad dentro del periodo.')\n",
    "fig.update_xaxes(nticks=20)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Días de la semana con mayor actividad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dayofweek(i):\n",
    "  l = [\"Lunes\", \"Martes\", \"Miércoes\", \"Jueves\", \"Viernes\", \"Sábado\", \"Domingo\"]\n",
    "  return l[i];\n",
    "day_df=pd.DataFrame(messages_df[\"Message\"])\n",
    "day_df['day_of_date'] = messages_df['Date'].dt.weekday\n",
    "day_df['day_of_date'] = day_df[\"day_of_date\"].apply(dayofweek)\n",
    "day_df[\"messagecount\"] = 1\n",
    "day = day_df.groupby(\"day_of_date\").sum()\n",
    "day.reset_index(inplace=True)\n",
    "\n",
    "fig = px.line_polar(day, r='messagecount', theta='day_of_date', line_close=True)\n",
    "fig.update_traces(fill='toself')\n",
    "fig.update_layout(\n",
    "  polar=dict(\n",
    "    radialaxis=dict(\n",
    "      visible=True,\n",
    "      range=[0,6000]\n",
    "    )),\n",
    "  showlegend=False\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Los 10 días de mayor actividad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_df['Date'].value_counts().head(10).plot.barh()\n",
    "plt.xlabel('Número de mensajes')\n",
    "plt.ylabel('Fecha')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Las horas del día con mayor frecuencia de mensajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_df['Time'].value_counts().head(10).plot.barh() \n",
    "plt.xlabel('Número de mensajes')\n",
    "plt.ylabel('Hora')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_df.iloc[messages_df['Word_Count'].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(review for review in messages_df.Message)\n",
    "print (\"Hay {} palabras en todos los mensajes.\".format(len(text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar una nube de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "from wordcloud import WordCloud \n",
    "stopwords = set(stopwords.words('spanish', 'english')) \n",
    "stopwords.update([ \"chingo\", \"xq\",\"aaay\",\"Jajajaa\",\"perra\",\"kieren\",\"verga\",\"inés\"])\n",
    "wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cloud(wordcloud):\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(40, 30))\n",
    "    # Display image\n",
    "    plt.imshow(wordcloud) \n",
    "    # No axis details\n",
    "    plt.axis(\"off\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate word cloud\n",
    "wordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Pastel1', collocations=False, stopwords = stopwords).generate(text)\n",
    "# Plot\n",
    "plot_cloud(wordcloud)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
